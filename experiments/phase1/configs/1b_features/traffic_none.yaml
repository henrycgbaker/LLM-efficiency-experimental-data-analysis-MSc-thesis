# Phase 1b.2: Traffic patterns - No simulation (baseline)
config_name: feature_traffic_none
model_name: meta-llama/Llama-3.2-1B

max_input_tokens: 128
max_output_tokens: 128
num_input_prompts: 64

gpus: [0]
num_processes: 1
num_cycles: 3

fp_precision: float16

batching:
  batch_size: 8
  strategy: static

decoder:
  preset: deterministic

quantization:
  quantization: false

traffic_simulation:
  enabled: false

prompts:
  type: huggingface
  dataset: ai-energy-score
  split: train
  sample_size: 64
